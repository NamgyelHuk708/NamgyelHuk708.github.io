---
Title: DAM101 Jounal_2
categories: [DAM101, Jounal_2]
tags: [DAM101]
---

# Topic : Data Preprocessing 
----

**What is Data and its two type**

Data is a word we hear everywhere nowadays. In general, data is a collection of facts, information, and statistics and this can be in various forms such as numbers, text, sound, images, video or any other format. And it has two type namily Structured data and Unstructured data.

1. Structured Data
- Organized in a clear, predefined format like tables.
- Easy to analyze and process.
- Examples: databases, spreadsheets.

2. Unstructured Data
- Lacks a predefined format or structure.
- Contains diverse, complex information like text, images,videos.
- Challenging to analyze and process directly.

It knows that AI are trained by feeding a combination of both structured and unstructured data allowing them to leverage the strengths of each type and produce more comprehensive results.

### Data Preprocessing

Like all even machine learning can learn and train faster if they are fed with structure and well formated datasets. 
Now what data preprocessing means is that its transforming of the data into a format that is easier and effective to be fed to AI which makees it easier for them to learn and to get accurte output.

### Introduction to NLP
Before diving into the specifics of text preprocessing and image preprocessing, it's essential to understand the significance of NLP and its applications. NLP deals with the interaction between computers and human (natural) languages, enabling machines to comprehend, interpret, and generate human-like text.

### Text preprocessing
Text preprocessing involves cleaning and standardizing text data before analysis or modeling. This process ensures consistency, improves analysis accuracy, and enhances the performance of natural language processing tasks like sentiment analysis(emotion analysis) and text classification.

### Techniques for Text Preprocessing

1. **Text Lowercasing**

**What:** Text lowering involves converting all letters in the text to lowercase. 

**Why**This is done to standardize the text and reduce the size of the vocabulary.Lowercasing ensures that words with different cases are treated uniformly.

**Example** 
importing neccesary libaries.
```
import nltk
import string
import re
```
We lowercase the text to reduce the size of the vocabulary of our text data.
```
def text_lowercase(text):
	return text.lower()

input_str = "Hey, did you know that the summer break is coming? Amazing right !! It's only 5 more days !!";
text_lowercase(input_str)
```
**Output:** “hey, did you know that the summer break is coming? amazing right!! it’s only 5 more days!!” 

2.**Removing Punctuation**

**What:**
Removing punctuation involves eliminating punctuation marks such as periods, commas, and exclamation points from the text. 
**Why:**
This is done to ensure consistency and avoid treating punctuated variations of words separately. 

**Example:**
```
def remove_punctuation(text):
	translator = str.maketrans('', '', string.punctuation)
	return text.translate(translator)
input_str = "Hey, did you know that the summer break is coming? Amazing right !! It's only 5 more days !!"
remove_punctuation(input_str)

```
**Output:** “Hey did you know that the summer break is coming Amazing right Its only 5 more days” 

3.**Removing White Space**

**What:**
Removing white space involves eliminating excess whitespace, including spaces, tabs, and newline characters, from the text.

**Why:**
 This is done to clean up the text and make it more readable. 

 **Example:**
 We can use the join and split function to remove all the white spaces in a string.
 ```
 # remove whitespace from text
def remove_whitespace(text):
	return " ".join(text.split())
input_str = "we don't need the given questions"
remove_whitespace(input_str)

 ```

4. **Removing Stopwords**

**What:**
Stopwords are common words like "the", "is", and "and" that occur frequently in the language but don't carry significant meaning.
**Why:**
Removing stopwords helps in focusing on content-bearing words and reducing noise in the text data. 
**Example:**
```
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# remove stopwords function
def remove_stopwords(text):
	stop_words = set(stopwords.words("english"))
	word_tokens = word_tokenize(text)
	filtered_text = [word for word in word_tokens if word not in stop_words]
	return filtered_text

example_text = "This is a sample sentence and we are going to remove the stopwords from this."
remove_stopwords(example_text)
```
**Input:**“This is a sample sentence and we are going to remove the stopwords from this” 

**Output:** [‘This’, ‘sample’, ‘sentence’, ‘going’, ‘remove’, ‘stopwords’] 

### Stemming v/s lemmatization

| Aspect | Stemming | Lemmatization |
| ----------- | ----------- | ----------- |
| Definition | Process of reducing words to their root form | Process of reducing words to their base or lemma |
| Root Word | Stem may not be a valid word | Lemma is always a valid word |
| Context Consideration | Does not consider the context of the word | Considers the context of the word |
| Language Preservation | May not preserve language integrity | Preserves language integrity |
| Efficiency | Generally faster | Can be slower due to context analysis |
| Example | Running -> Run, books -> book  | 	Running -> Run, Better -> Good |